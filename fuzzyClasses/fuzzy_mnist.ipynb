{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for testing mnist when using fuzzy class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime, os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (42000, 28, 28, 1)\n",
      "42000 train samples\n",
      "18000 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.7, random_state=2019, stratify=y_train)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_val /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'validation samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/329 [..............................] - ETA: 0s - loss: 2.3275 - accuracy: 0.0547WARNING:tensorflow:From C:\\Users\\jj364\\Documents\\deep_learning\\dl\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/329 [..............................] - ETA: 20s - loss: 2.3188 - accuracy: 0.0859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.1070s). Check your callbacks.\n",
      "329/329 [==============================] - 4s 13ms/step - loss: 2.2906 - accuracy: 0.1352 - val_loss: 2.2672 - val_accuracy: 0.2496\n",
      "Epoch 2/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 2.2584 - accuracy: 0.2019 - val_loss: 2.2291 - val_accuracy: 0.3661\n",
      "Epoch 3/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 2.2193 - accuracy: 0.2777 - val_loss: 2.1842 - val_accuracy: 0.4754\n",
      "Epoch 4/20\n",
      "329/329 [==============================] - 4s 11ms/step - loss: 2.1726 - accuracy: 0.3424 - val_loss: 2.1278 - val_accuracy: 0.5648\n",
      "Epoch 5/20\n",
      "329/329 [==============================] - 3s 11ms/step - loss: 2.1155 - accuracy: 0.3992 - val_loss: 2.0567 - val_accuracy: 0.6192\n",
      "Epoch 6/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 2.0423 - accuracy: 0.4560 - val_loss: 1.9676 - val_accuracy: 0.6610\n",
      "Epoch 7/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 1.9540 - accuracy: 0.5006 - val_loss: 1.8594 - val_accuracy: 0.6995\n",
      "Epoch 8/20\n",
      "329/329 [==============================] - 3s 11ms/step - loss: 1.8492 - accuracy: 0.5403 - val_loss: 1.7323 - val_accuracy: 0.7266\n",
      "Epoch 9/20\n",
      "329/329 [==============================] - 4s 11ms/step - loss: 1.7304 - accuracy: 0.5698 - val_loss: 1.5924 - val_accuracy: 0.7455\n",
      "Epoch 10/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 1.6065 - accuracy: 0.5969 - val_loss: 1.4471 - val_accuracy: 0.7594\n",
      "Epoch 11/20\n",
      "329/329 [==============================] - 4s 11ms/step - loss: 1.4811 - accuracy: 0.6171 - val_loss: 1.3063 - val_accuracy: 0.7717\n",
      "Epoch 12/20\n",
      "329/329 [==============================] - 4s 11ms/step - loss: 1.3686 - accuracy: 0.6356 - val_loss: 1.1782 - val_accuracy: 0.7842\n",
      "Epoch 13/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 1.2674 - accuracy: 0.6526 - val_loss: 1.0661 - val_accuracy: 0.7934\n",
      "Epoch 14/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 1.1790 - accuracy: 0.6687 - val_loss: 0.9712 - val_accuracy: 0.8025\n",
      "Epoch 15/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 1.1035 - accuracy: 0.6854 - val_loss: 0.8925 - val_accuracy: 0.8096\n",
      "Epoch 16/20\n",
      "329/329 [==============================] - 4s 11ms/step - loss: 1.0422 - accuracy: 0.6968 - val_loss: 0.8274 - val_accuracy: 0.8167\n",
      "Epoch 17/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 0.9876 - accuracy: 0.7081 - val_loss: 0.7733 - val_accuracy: 0.8234\n",
      "Epoch 18/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 0.9367 - accuracy: 0.7218 - val_loss: 0.7275 - val_accuracy: 0.8293\n",
      "Epoch 19/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 0.8988 - accuracy: 0.7297 - val_loss: 0.6889 - val_accuracy: 0.8336\n",
      "Epoch 20/20\n",
      "329/329 [==============================] - 3s 10ms/step - loss: 0.8643 - accuracy: 0.7381 - val_loss: 0.6561 - val_accuracy: 0.8384\n",
      "Test loss: 0.6308640241622925\n",
      "Test accuracy: 0.8519999980926514\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[tensorboard_callback])\n",
    "## Let's use Tensorboard to keep track of things\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 21100."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs  # Start Tensorboard if you want to see graphical training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's split the data into two train/val splits with a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_a: 21000 val_a: 9000 train_b: 21000 val_b: 9000 test: 5000 test_fin: 5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# n_samples = np.zeros(10)\n",
    "# for i in range(x_test.shape[0]):\n",
    "#     result = model.predict(np.expand_dims(x_test[i],axis=0))\n",
    "#     result_val = np.argmax(result)\n",
    "#     ground_truth = np.argmax(y_test_a[i])\n",
    "#     uncertainty_matrix[ground_truth,:] += result[0]\n",
    "#     n_samples[ground_truth] += 1\n",
    "# print(n_samples)\n",
    "\n",
    "train_size = 0.7\n",
    "x_train_a, x_train_b, y_train_a, y_train_b = train_test_split(x_train, y_train, train_size=0.5, random_state=2019, stratify=y_train)\n",
    "x_train_a, x_val_a, y_train_a, y_val_a = train_test_split(x_train_a, y_train_a, train_size=0.7, random_state=325, stratify=y_train_a)\n",
    "x_train_b, x_val_b, y_train_b, y_val_b = train_test_split(x_train_b, y_train_b, train_size=0.7, random_state=325, stratify=y_train_b)\n",
    "x_test, x_test_fin, y_test, y_test_fin = train_test_split(x_test, y_test, train_size=0.5, random_state=325, stratify=y_test)\n",
    "\n",
    "# I know it's channels last\n",
    "x_train_a = x_train_a.reshape(x_train_a.shape[0], img_rows, img_cols, 1)\n",
    "x_val_a = x_val_a.reshape(x_val_a.shape[0], img_rows, img_cols, 1)\n",
    "x_train_b = x_train_b.reshape(x_train_b.shape[0], img_rows, img_cols, 1)\n",
    "x_val_b = x_val_b.reshape(x_val_b.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "x_test_fin = x_test_fin.reshape(x_test_fin.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train_a = x_train_a.astype('float32'); x_train_b = x_train_b.astype('float32'); x_val_a = x_val_a.astype('float32'); x_val_b = x_val_b.astype('float32')\n",
    "x_test = x_test.astype('float32'); x_test_fin = x_test_fin.astype('float32')\n",
    "x_train_a /= 255; x_train_b /= 255; x_val_a /= 255; x_val_b /= 255\n",
    "x_test /= 255; x_test_fin /= 255\n",
    "print('train_a: %i val_a: %i train_b: %i val_b: %i test: %i test_fin: %i' %(x_train_a.shape[0], x_val_a.shape[0], x_train_b.shape[0], x_val_b.shape[0], x_test.shape[0], x_test_fin.shape[0]))\n",
    "\n",
    "y_train_a = keras.utils.to_categorical(y_train_a, num_classes)\n",
    "y_val_a = keras.utils.to_categorical(y_val_a, num_classes)\n",
    "y_train_b = keras.utils.to_categorical(y_train_b, num_classes)\n",
    "y_val_b = keras.utils.to_categorical(y_val_b, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_test_fin = keras.utils.to_categorical(y_test_fin, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuse model from before to train\n",
    "Use fewer epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "165/165 [==============================] - 2s 12ms/step - loss: 2.3172 - accuracy: 0.0907 - val_loss: 2.3051 - val_accuracy: 0.1363\n",
      "Epoch 2/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.2994 - accuracy: 0.1224 - val_loss: 2.2864 - val_accuracy: 0.1832\n",
      "Epoch 3/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.2818 - accuracy: 0.1486 - val_loss: 2.2673 - val_accuracy: 0.1957\n",
      "Epoch 4/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.2645 - accuracy: 0.1802 - val_loss: 2.2473 - val_accuracy: 0.2114\n",
      "Epoch 5/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.2453 - accuracy: 0.2065 - val_loss: 2.2261 - val_accuracy: 0.2376\n",
      "Epoch 6/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.2257 - accuracy: 0.2344 - val_loss: 2.2032 - val_accuracy: 0.2751\n",
      "Epoch 7/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.2023 - accuracy: 0.2691 - val_loss: 2.1775 - val_accuracy: 0.3228\n",
      "Epoch 8/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.1797 - accuracy: 0.2920 - val_loss: 2.1486 - val_accuracy: 0.3846\n",
      "Epoch 9/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.1518 - accuracy: 0.3263 - val_loss: 2.1164 - val_accuracy: 0.4606\n",
      "Epoch 10/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.1194 - accuracy: 0.3622 - val_loss: 2.0801 - val_accuracy: 0.5251\n",
      "Epoch 11/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.0867 - accuracy: 0.3907 - val_loss: 2.0399 - val_accuracy: 0.5780\n",
      "Epoch 12/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 2.0476 - accuracy: 0.4237 - val_loss: 1.9953 - val_accuracy: 0.6158\n",
      "Epoch 13/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 2.0038 - accuracy: 0.4542 - val_loss: 1.9464 - val_accuracy: 0.6469\n",
      "Epoch 14/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 1.9621 - accuracy: 0.4781 - val_loss: 1.8940 - val_accuracy: 0.6744\n",
      "Epoch 15/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.9135 - accuracy: 0.5007 - val_loss: 1.8373 - val_accuracy: 0.6972\n",
      "Epoch 16/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.8582 - accuracy: 0.5272 - val_loss: 1.7765 - val_accuracy: 0.7199\n",
      "Epoch 17/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.8062 - accuracy: 0.5435 - val_loss: 1.7129 - val_accuracy: 0.7367\n",
      "Epoch 18/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.7472 - accuracy: 0.5615 - val_loss: 1.6470 - val_accuracy: 0.7499\n",
      "Epoch 19/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.6883 - accuracy: 0.5802 - val_loss: 1.5793 - val_accuracy: 0.7582\n",
      "Epoch 20/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.6298 - accuracy: 0.5938 - val_loss: 1.5106 - val_accuracy: 0.7646\n",
      "Test loss: 1.5018641948699951\n",
      "Test accuracy: 0.7742000222206116\n"
     ]
    }
   ],
   "source": [
    "model_set_vals = Sequential()\n",
    "model_set_vals.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model_set_vals.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_set_vals.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_set_vals.add(Dropout(rate=0.25))\n",
    "model_set_vals.add(Flatten())\n",
    "model_set_vals.add(Dense(128, activation='relu'))\n",
    "model_set_vals.add(Dropout(rate=0.5))\n",
    "model_set_vals.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_set_vals.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_set_vals.fit(x_train_a, y_train_a,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val_a, y_val_a))\n",
    "score = model_set_vals.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "cm = cm/cm.sum(axis=1)\n",
    "classes = np.arange(0,10,1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "# We want to show all ticks...\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       # ... and label them with the respective list entries\n",
    "       xticklabels=classes, yticklabels=classes,\n",
    "       ylabel='True label',\n",
    "       xlabel='Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_b_nothot = np.ndarray((y_train_b.shape))\n",
    "for i in range(y_train_b.shape[0]):\n",
    "    loc = np.argmax(y_train_b[i])\n",
    "    y_train_b_nothot[i,:] = cm[loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 2.3001 - accuracy: 0.0991 - val_loss: 2.2852 - val_accuracy: 0.0904\n",
      "Epoch 2/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.2750 - accuracy: 0.1253 - val_loss: 2.2588 - val_accuracy: 0.1737\n",
      "Epoch 3/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.2514 - accuracy: 0.1589 - val_loss: 2.2320 - val_accuracy: 0.3024\n",
      "Epoch 4/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.2275 - accuracy: 0.1958 - val_loss: 2.2038 - val_accuracy: 0.3897\n",
      "Epoch 5/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 2.2021 - accuracy: 0.2408 - val_loss: 2.1732 - val_accuracy: 0.4789\n",
      "Epoch 6/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 2.1748 - accuracy: 0.2788 - val_loss: 2.1396 - val_accuracy: 0.5421\n",
      "Epoch 7/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 2.1453 - accuracy: 0.3191 - val_loss: 2.1031 - val_accuracy: 0.5809\n",
      "Epoch 8/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 2.1126 - accuracy: 0.3593 - val_loss: 2.0632 - val_accuracy: 0.6189\n",
      "Epoch 9/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.0797 - accuracy: 0.3916 - val_loss: 2.0194 - val_accuracy: 0.6473\n",
      "Epoch 10/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.0412 - accuracy: 0.4310 - val_loss: 1.9713 - val_accuracy: 0.6647\n",
      "Epoch 11/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 2.0022 - accuracy: 0.4557 - val_loss: 1.9195 - val_accuracy: 0.6774\n",
      "Epoch 12/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.9618 - accuracy: 0.4744 - val_loss: 1.8645 - val_accuracy: 0.6869\n",
      "Epoch 13/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.9152 - accuracy: 0.5027 - val_loss: 1.8057 - val_accuracy: 0.6953\n",
      "Epoch 14/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.8683 - accuracy: 0.5213 - val_loss: 1.7438 - val_accuracy: 0.7010\n",
      "Epoch 15/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.8240 - accuracy: 0.5351 - val_loss: 1.6803 - val_accuracy: 0.7074\n",
      "Epoch 16/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.7749 - accuracy: 0.5500 - val_loss: 1.6165 - val_accuracy: 0.7140\n",
      "Epoch 17/20\n",
      "165/165 [==============================] - 2s 9ms/step - loss: 1.7272 - accuracy: 0.5655 - val_loss: 1.5524 - val_accuracy: 0.7172\n",
      "Epoch 18/20\n",
      "165/165 [==============================] - 2s 10ms/step - loss: 1.6819 - accuracy: 0.5769 - val_loss: 1.4889 - val_accuracy: 0.7211\n",
      "Epoch 19/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 1.6390 - accuracy: 0.5897 - val_loss: 1.4271 - val_accuracy: 0.7256\n",
      "Epoch 20/20\n",
      "165/165 [==============================] - 2s 11ms/step - loss: 1.6009 - accuracy: 0.5959 - val_loss: 1.3682 - val_accuracy: 0.7302\n"
     ]
    }
   ],
   "source": [
    "model_nothot = Sequential()\n",
    "model_nothot.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model_nothot.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_nothot.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_nothot.add(Dropout(rate=0.25))\n",
    "model_nothot.add(Flatten())\n",
    "model_nothot.add(Dense(128, activation='relu'))\n",
    "model_nothot.add(Dropout(rate=0.5))\n",
    "model_nothot.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_nothot.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_nothot.fit(x_train_b, y_train_b_nothot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val_b, y_val_b))\n",
    "score_nothot = model_nothot.evaluate(x_test_fin, y_test_fin, verbose=0)\n",
    "score_set = model_set_vals.evaluate(x_test_fin, y_test_fin, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss set: 1.49983 nothot: 1.35040 original: 0.62941\n",
      "Test accuracy set: 0.77940 nothot 0.75580 original: 0.85640\n"
     ]
    }
   ],
   "source": [
    "final_score = score = model.evaluate(x_test_fin, y_test_fin, verbose=0)\n",
    "print('Test loss set: %.5f nothot: %.5f original: %.5f' %(score_set[0],score_nothot[0], final_score[0]))\n",
    "print('Test accuracy set: %.5f nothot %.5f original: %.5f'%(score_set[1],score_nothot[1], final_score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
